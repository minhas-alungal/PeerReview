{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automation for Peer Review Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Changes To Be Made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 2nd cell start_date, end_date, month, year, week and percent values must be changed.\n",
    "Also remove member name from the \"reviewers\" list if member data is not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../January_2020/week5\n"
     ]
    }
   ],
   "source": [
    "#As peer review is performed weekly, individual member files are kept in respective month and week folder\n",
    "#dates in mmddyyyy format\n",
    "start_date=\"01272020\"\n",
    "end_date=\"01312020\"\n",
    "month=\"January\"\n",
    "year=\"2020\"\n",
    "week=\"week5\"\n",
    "percent=0.2 #percent of data to be peer reviewed\n",
    "file_name=start_date+'_'+end_date\n",
    "path=\"../\"+month+\"_\"+year+\"/\"+week\n",
    "reviewers=['SP','GP','PK','MA']\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../January_2020/week5\\\\week5_GP.xlsx',\n",
       " '../January_2020/week5\\\\week5_MA.xlsx',\n",
       " '../January_2020/week5\\\\week5_PK.xlsx',\n",
       " '../January_2020/week5\\\\week5_SP.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(path+'/'+week+'*.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending individual member data and creating a compiled csv file\n",
    "MTM_data = pd.DataFrame()\n",
    "for f in glob.glob(path+'/'+week+'*.xlsx'):\n",
    "    member_data = pd.read_excel(f,index_col = None)\n",
    "    MTM_data = MTM_data.append(member_data,  ignore_index=True, sort=False)\n",
    "writer = pd.ExcelWriter(path+'/'+file_name+'.xlsx', engine='xlsxwriter')\n",
    "MTM_data.to_csv(path+'/'+file_name+'.csv', encoding='utf-8')\n",
    "print('Dimensions of MTM_data:',MTM_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the column names of the data\n",
    "MTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the Matched column on space to get the exact status of the title\n",
    "MTM_data['Status'] = MTM_data['Matches'].str.split(' ').str[0]\n",
    "MTM_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the unique values in the status column\n",
    "MTM_data['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the names of status as per requirement\n",
    "MTM_data['Status'].replace('Already', 'Already_Matched', inplace= True)\n",
    "MTM_data['Status'].replace('Not', 'Not_Worked', inplace = True)\n",
    "MTM_data['Status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a key of By and Status column\n",
    "MTM_data['key'] = MTM_data['Status'].astype(str) + '_' +MTM_data['By'].astype(str)\n",
    "MTM_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the random number against each title and sort the\n",
    "random.seed(42)\n",
    "MTM_data['Rnos'] = [random.random() for k in MTM_data.index]\n",
    "MTM_data.sort_values(['key','Rnos'],ascending=[True, False],inplace=True)\n",
    "MTM_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count each category belongs to 'key' column and put that in the new column\n",
    "MTM_data['Total_Tiltes_worked'] = MTM_data.groupby('key')['key'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new dataframe which gives the unique values in key and Total_Tiltes_worked columns\n",
    "distribution_of_key=MTM_data.drop_duplicates(['key','Total_Tiltes_worked'])[['key','Total_Tiltes_worked']]\n",
    "distribution_of_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the key to get the Already status seperately\n",
    "distribution_of_key['status_first_word'] = distribution_of_key['key'].str.split('_').str[0]\n",
    "distribution_of_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning percentages against each key\n",
    "distribution_of_key['percentage'] = np.where(distribution_of_key['status_first_word']=='Already', 0.05, percent)\n",
    "distribution_of_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculating the exact number of titles for each key for assigned percentage\n",
    "distribution_of_key['20percent_of_total_titles'] = round(distribution_of_key['Total_Tiltes_worked']*distribution_of_key['percentage'],ndigits=0)\n",
    "distribution_of_key['20percent_of_total_titles'].replace(0,1,inplace = True)\n",
    "distribution_of_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the main data(MTM_data) with distribution data to get the 20percent of titles in the main data\n",
    "MTM_data = pd.merge(MTM_data,distribution_of_key[['key','20percent_of_total_titles']], how='left', on='key')\n",
    "MTM_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a new column 'count' where we are distributing total_titles_worked column based on the values in the column from 1 to n where n is the count of key in the dataframe\n",
    "MTM_data['count'] = 1\n",
    "for i in range(len(MTM_data)-1):\n",
    "    if MTM_data.ix[i+1,'key'] == MTM_data.ix[i,'key']:\n",
    "        MTM_data.ix[i+1,'count'] = MTM_data.ix[i,'count']+1\n",
    "    else:\n",
    "        MTM_data.ix[i+1,'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTM_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding column of which titles to check for peer review\n",
    "MTM_data['Titles_to_check'] = MTM_data.apply(lambda x: 'to_recheck' if x['count'] <= x['20percent_of_total_titles'] else 'not to_recheck', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting rows with only 'to_recheck' status and making the final data\n",
    "MTM_data_final = MTM_data[MTM_data['Titles_to_check'] == 'to_recheck']\n",
    "print('Dimensions of MTM_data_final:',MTM_data_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count total already matched titles\n",
    "distribution_of_key_already_matched = distribution_of_key[distribution_of_key['status_first_word'] == 'Already']\n",
    "Total_Already_Matched_Titles = round((distribution_of_key_already_matched['20percent_of_total_titles'].sum()),ndigits=0)\n",
    "print('Total Already Matched Titles:',Total_Already_Matched_Titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count total rest matched titles\n",
    "distribution_of_key_rest_matched = distribution_of_key[distribution_of_key['status_first_word'] != 'Already']\n",
    "Total_Rest_Matched_Titles = round((distribution_of_key_rest_matched['20percent_of_total_titles'].sum()),ndigits=0)\n",
    "print('Total Rest Matched Titles:',Total_Rest_Matched_Titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count total titles to recheck\n",
    "Total_Titles_to_recheck = Total_Already_Matched_Titles + Total_Rest_Matched_Titles\n",
    "print('Total_Titles_to_recheck:',Total_Titles_to_recheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QC of total number of titles to recheck in the final dataframe and total number of titles to recheck counted from the individual distribution of percentages for each key\n",
    "QC = len(MTM_data_final) - Total_Titles_to_recheck\n",
    "if QC == 0:\n",
    "    print('Correct calculation')\n",
    "else:\n",
    "    print('Error in the calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTM_data_final=MTM_data_final.drop(['Rnos','Total_Tiltes_worked','key','20percent_of_total_titles','count','Titles_to_check','Status' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export final data which need to recheck\n",
    "MTM_data_final.to_csv(path+'/'+file_name+'_verify.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign=MTM_data_final.sort_values(\"By\")\n",
    "assign= assign.groupby(['By']) \n",
    "\n",
    "#MTM_data_final[MTM_data_final[\"By\"]==\"SP\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating each members data\n",
    "names={}\n",
    "for i in reviewers:\n",
    "    df=assign.get_group(i)\n",
    "    names.update({i:df})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing each members data so that it can distributed equally among other members for verification\n",
    "#SP['Rnos'] = 0\n",
    "members=names.values()\n",
    "num=[]\n",
    "for i in range(len(members)):\n",
    "    num.append(i)\n",
    "del num[0]\n",
    "c=0\n",
    "for j in members:\n",
    "    for i in j.index :\n",
    "        j.loc[i, \"Rnos\"]=num[c]\n",
    "        if c==len(num)-1:\n",
    "            c=0\n",
    "        else:\n",
    "            c=c+1 \n",
    "    \n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which creates verification file for each member on passing the names dictionary as argument\n",
    "\n",
    "def verify(names):\n",
    "    counter={}\n",
    "    names_set=set(names)\n",
    "    \n",
    "    #Initialising counter dictionary with key as member name and value as 1\n",
    "    for val in names:\n",
    "        temp={val:1}\n",
    "        counter.update(temp)\n",
    "       \n",
    "        \n",
    "    \n",
    "    for person, data in names.items() :\n",
    "        \n",
    "        verify_file_name=person\n",
    "        verifier={person}\n",
    "        verification_set=names_set-verifier\n",
    "        print(verification_set)\n",
    "        #verify dictionary has verifier name as key and verification names as values\n",
    "        verify={person:verification_set}\n",
    "        print(verify)\n",
    "        verification_file=pd.DataFrame()\n",
    "        print('*****************')\n",
    "        for people in verification_set :\n",
    "            print(people)\n",
    "            counter_val=counter[people]\n",
    "            people_data=names[people]\n",
    "            person=people_data[people_data[\"Rnos\"]==counter_val]\n",
    "            #print(person, each, counter_val)\n",
    "            verification_file=verification_file.append(person)\n",
    "            verification_file.to_csv(path+'/'+file_name+'_'+str(verify_file_name)+'_verify.csv')\n",
    "            counter_val=counter_val+1\n",
    "            up={people:counter_val}\n",
    "            counter.update(up)\n",
    "            \n",
    "\n",
    "            \n",
    "verify(names)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
